ELMo(Embeddings from Language Models)是AllenNLP开发的一种NLP架构，是一种在词向量和词嵌入中表达词汇的方法。

ELMo的工作原理：ELMo的词向量是在双层双向语言模型（two-layer bidirectional language model，biLM）上计算的，每层都有前向和后向两种迭代。

首先使用CNN将文本中的词转换为原始词向量，再将这些词向量输入到双向语言模型第一层。前向迭代中包含了该词及之前的的词汇或语境信息，后向迭代中包含了该词之后的信息。这两种信息组成了中间词向量，并运送到模型的下一层。最终ELMo词向量就是原始词向量和两个中间词向量的加权和。此外，因为双向语言模型输入的量度是字符，所以能获取词的内部结构信息，能识别出一些词的相关性。

与word2vec等传统词嵌入不同，EMLo每个词向量实际上是一个包含该词的句子的函数，同一个词在不同的上下文会有不同的词向量。

